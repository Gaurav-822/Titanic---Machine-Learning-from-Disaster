# Titanic Survival Prediction

## Project Overview

This project aims to predict the survival of passengers aboard the Titanic using machine learning. The goal is to build a binary classification model that determines whether a passenger survived based on features like their sex and passenger class. The dataset is the classic "Titanic - Machine Learning from Disaster" challenge from Kaggle.

This notebook walks through the process of Exploratory Data Analysis (EDA), data preprocessing, building a neural network model with TensorFlow/Keras, and generating a submission file.

---

## File Structure

The project directory is organized as follows:

-   `titanic.ipynb`: The main Jupyter Notebook containing all the code for data analysis, preprocessing, model training, and prediction.
-   `train.csv`: The training dataset containing passenger information and their survival status.
-   `test.csv`: The test dataset used for generating predictions.
-   `gender_submission.csv`: An example submission file provided by Kaggle, used here for final accuracy validation.
-   `submission.csv`: The final output file generated by the model with predictions for the test dataset.
-   `titanic_model.h5`: The saved, trained Keras model file.
-   `.gitignore`: A file to specify untracked files that Git should ignore.

---

## Methodology

The prediction workflow is detailed in `titanic.ipynb` and follows these key steps:

### 1. Exploratory Data Analysis (EDA)

The initial analysis involved exploring the `train.csv` dataset to understand feature distributions and relationships. Key findings include:

-   **Gender Impact:** A strong correlation exists between sex and survival. Females had a much higher survival rate (**74.2%**) compared to males (**18.9%**).
-   **Fare Distribution:** Passengers who paid a lower fare had a lower survival rate.
-   **Embarkation Port:** Survival rates varied slightly depending on the port of embarkation (C=Cherbourg, Q=Queenstown, S=Southampton).
-   **Feature Correlation:** A heatmap of numeric features showed a notable negative correlation between `Pclass` (Passenger Class) and `Survived`.


### 2. Data Preprocessing

Based on the EDA, a simple yet powerful feature set was selected for the final model: `Sex` and `Pclass`.

-   **Feature Selection:** Chose `Survived`, `Sex`, and `Pclass` as the most influential features.
-   **Categorical Conversion:** The `Sex` column was converted from categorical ('male', 'female') to numerical (0, 1).
-   **One-Hot Encoding:** The `Pclass` column, representing passenger class (1, 2, 3), was one-hot encoded to prevent the model from assuming an ordinal relationship.

### 3. Model Building & Training

A simple sequential neural network was built using TensorFlow/Keras.

-   **Architecture:**
    -   Input Layer: Dense layer with 8 neurons (`relu` activation).
    -   Dropout Layer: 20% dropout for regularization.
    -   Hidden Layer: Dense layer with 4 neurons (`relu` activation).
    -   Dropout Layer: 20% dropout.
    -   Output Layer: Dense layer with 1 neuron (`sigmoid` activation) for binary classification.
-   **Compilation:** The model was compiled with the `adam` optimizer and `binary_crossentropy` loss function, suitable for this task.
-   **Data Splitting:** The training data was shuffled and split into training (80%), validation (10%), and evaluation (10%) sets.
-   **Training:** The model was trained for 50 epochs. The training and validation loss were plotted to monitor for overfitting.


### 4. Prediction & Submission

The trained model (`titanic_model.h5`) was used to predict survival for the passengers in `test.csv`. The final predictions were compiled into `submission.csv` in the required format for the Kaggle competition.

---

## Results

The model's performance was evaluated on multiple datasets:

-   **Validation Accuracy (during training):** **75.28%**
-   **Evaluation Accuracy (unseen 10% split):** **86.67%**
-   **Final Kaggle Submission Score:** **77.511%**

The final score on the Kaggle test set demonstrates a solid predictive performance. This result confirms that using a simple feature set of just Sex and Pclass is a powerful approach for this particular problem, highlighting the significant impact these factors had on survival rates aboard the Titanic.
---

## How to Run

To run this project, follow these steps:

1.  **Clone the repository:**
    ```bash
    git clone <repository-url>
    cd <repository-directory>
    ```

2.  **Set up a virtual environment:**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows, use `venv\Scripts\activate`
    ```

3.  **Install dependencies:**
    *(Create a `requirements.txt` file with pandas, matplotlib, and tensorflow)*
    ```bash
    pip install pandas matplotlib tensorflow
    ```

4.  **Launch Jupyter Notebook:**
    ```bash
    jupyter notebook
    ```

5.  **Run the notebook:**
    Open `titanic.ipynb` and run the cells sequentially.
